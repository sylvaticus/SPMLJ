<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>0502x EXERCISE-5.1 Â· SPMLJ</title><script async src="https://www.googletagmanager.com/gtag/js?id=G-Q39LHCRBB6"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-Q39LHCRBB6', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">SPMLJ</a></span></div><form class="docs-search" action="../search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Index</a></li><li><span class="tocitem">Lessons</span><ul><li><input class="collapse-toggle" id="menuitem-2-1" type="checkbox"/><label class="tocitem" for="menuitem-2-1"><span class="docs-label">INTRO - Introduction to the course, Julia and ML</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html">0001 - Course presentation</a></li><li><a class="tocitem" href="../00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html">0002 - Program</a></li><li><a class="tocitem" href="../00_-_INTRO_-_Introduction_julia_ml/0003_-_Introduction_to_Julia.html">0003 - Introduction to Julia</a></li><li><a class="tocitem" href="../00_-_INTRO_-_Introduction_julia_ml/0004_-_Introduction_to_ML.html">0004 - Introduction to ML</a></li><li><a class="tocitem" href="../00_-_INTRO_-_Introduction_julia_ml/0004q_-_QUIZ_0.1.html">0004q - QUIZ 0.1</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">JULIA1 - Basic Julia programming</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html">0101 - Basic syntax</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0101q_-_QUIZ_1.1.html">0101q - QUIZ 1.1</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0101q_-_QUIZ_1.2.html">0101q - QUIZ 1.2</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0102_-_Types_and_objects.html">0102 - Types and objects</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0102q_-_QUIZ_1.3.html">0102q - QUIZ 1.3</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0103_-_Predefined_types.html">0103 - Predefined types</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0103q_-_QUIZ_1.4.html">0103q - QUIZ 1.4</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0103q_-_QUIZ_1.5.html">0103q - QUIZ 1.5</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0103q_-_QUIZ_1.6.html">0103q - QUIZ 1.6</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0104_-_Control_flow_and_functions.html">0104 - Control flow and functions</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0104q_-_QUIZ_1.7.html">0104q - QUIZ 1.7</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0104q_-_QUIZ_1.8.html">0104q - QUIZ 1.8</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0105_-_Custom_types.html">0105 - Custom types</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0105q_-_QUIZ_1.10.html">0105q - QUIZ 1.10</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0105q_-_QUIZ_1.9.html">0105q - QUIZ 1.9</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0105x_EXERCISE-1.1.html">0105x EXERCISE-1.1</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0106_-_Further_topics.html">0106 - Further topics</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0106q_-_QUIZ_1.11.html">0106q - QUIZ 1.11</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0106q_-_QUIZ_1.12.html">0106q - QUIZ 1.12</a></li><li><a class="tocitem" href="../01_-_JULIA1_-_Basic_Julia_programming/0106q_-_QUIZ_1.13.html">0106q - QUIZ 1.13</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">JULIA2 - Scientific programming with Julia</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../02_-_JULIA2_-_Scientific_programming_with_Julia/0201_-_Wranging_data.html">0201 - Wranging data</a></li><li><a class="tocitem" href="../02_-_JULIA2_-_Scientific_programming_with_Julia/0202_-_Miscellaneous_topics.html">0202 - Miscellaneous topics</a></li><li><a class="tocitem" href="../02_-_JULIA2_-_Scientific_programming_with_Julia/0202x_EXERCISE-2.1.html">0202x EXERCISE-2.1</a></li><li><a class="tocitem" href="../02_-_JULIA2_-_Scientific_programming_with_Julia/0202x_EXERCISE-2.2.html">0202x EXERCISE-2.2</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">ML1 - Introduction to Machine Learning</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../03_-_ML1_-_Introduction_to_Machine_Learning/0301_-_Machine_learning_main_concepts.html">0301 - Machine learning main concepts</a></li><li><a class="tocitem" href="../03_-_ML1_-_Introduction_to_Machine_Learning/0302_-_The_Perceptron_classifier.html">0302 - The Perceptron classifier</a></li><li><a class="tocitem" href="../03_-_ML1_-_Introduction_to_Machine_Learning/0302x_EXERCISE-3.1.html">0302x EXERCISE-3.1</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-5" type="checkbox"/><label class="tocitem" for="menuitem-2-5"><span class="docs-label">NN - Neural Networks</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../04_-_NN_-_Neural_Networks/0401_-_Neural_network_architectures.html">0401 - Neural network architectures</a></li><li><a class="tocitem" href="../04_-_NN_-_Neural_Networks/0402_-_Implementation_of_neural_networks_workflows.html">0402 - Implementation of neural networks workflows</a></li><li><a class="tocitem" href="../04_-_NN_-_Neural_Networks/0402x_EXERCISE-4.1.html">0402x EXERCISE-4.1</a></li><li><a class="tocitem" href="../04_-_NN_-_Neural_Networks/0402x_EXERCISE-4.2.html">0402x EXERCISE-4.2</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-6" type="checkbox" checked/><label class="tocitem" for="menuitem-2-6"><span class="docs-label">DT - Decision trees based algorithms</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="0501_-_Decision_trees_based_algorithms.html">0501 - Decision trees based algorithms</a></li><li class="is-active"><a class="tocitem" href="0502x_EXERCISE-5.1.html">0502x EXERCISE-5.1</a><ul class="internal"><li><a class="tocitem" href="#Instructions"><span>Instructions</span></a></li><li><a class="tocitem" href="#Resolution"><span>Resolution</span></a></li></ul></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Lessons</a></li><li><a class="is-disabled">DT - Decision trees based algorithms</a></li><li class="is-active"><a href="0502x_EXERCISE-5.1.html">0502x EXERCISE-5.1</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="0502x_EXERCISE-5.1.html">0502x EXERCISE-5.1</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/sylvaticus/SPMLJ/blob/master/lessonsSources/05_-_DT_-_Decision_trees_based_algorithms/0502x_EXERCISE-5.1.md" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="EXERCISE-5.1:-Predicting-credit-approval-with-a-Random-Forest-model"><a class="docs-heading-anchor" href="#EXERCISE-5.1:-Predicting-credit-approval-with-a-Random-Forest-model">EXERCISE 5.1: Predicting credit approval with a Random Forest model</a><a id="EXERCISE-5.1:-Predicting-credit-approval-with-a-Random-Forest-model-1"></a><a class="docs-heading-anchor-permalink" href="#EXERCISE-5.1:-Predicting-credit-approval-with-a-Random-Forest-model" title="Permalink"></a></h1><p>&nbsp;</p>
<img src="imgs/errorByNumberOfTrees.png" alt="Error per number of trees" style="height:250px;"> 
<img src="imgs/errorByMaxFeatures.png" alt="Error per maxFeatures" style="height:250px;"> 
<p>&nbsp;</p><p>In this exercise we will implement a Machine Learning workflow to predict the positive or negative outcome of credit applications on the basis of the applicant characteristics. As the data comes from a real-world log from a financial institution, both fields&#39; names and values have been replaced with meaningless symbols to preserve anonymity. </p><p>In detail, the attributes of this dataset are:</p><ul><li>A1: b, a.</li><li>A2: continuous.</li><li>A3: continuous.</li><li>A4: u, y, l, t.</li><li>A5: g, p, gg.</li><li>A6: c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.</li><li>A7: v, h, bb, j, n, z, dd, ff, o.</li><li>A8: continuous.</li><li>A9: t, f.</li><li>A10: t, f.</li><li>A11: continuous.</li><li>A12: t, f.</li><li>A13: g, p, s.</li><li>A14: continuous.</li><li>A15: continuous.</li><li>A16: +,- (class attribute) - what we want to predict</li></ul><p>Further information concerning this dataset can be found online on the <a href="https://archive.ics.uci.edu/ml/datasets/Credit+Approval">UCI Machine Learning Repository dedicated page</a></p><p>Our prediction concerns the positive or negative outcome of the credit application.</p><p>While we could have used any supervised ML algorithm, it is suggested to work here with <a href="https://sylvaticus.github.io/BetaML.jl/dev/Trees.html"><code>Random Forests</code></a> from BetaML because of their ease of use and the presence of numerous categorical data and missing data that would require additional work with most other algorithms.</p><p><strong>Skills employed:</strong></p><ul><li>download and import data from internet</li><li>train a Random Forest model for classification using <code>BetaML</code></li><li>tune the various Random Forest hyper-parameters using cross-validation</li><li>use the additional <code>BetaML</code> functions <code>partition</code> and <code>accuracy</code>,</li></ul><h2 id="Instructions"><a class="docs-heading-anchor" href="#Instructions">Instructions</a><a id="Instructions-1"></a><a class="docs-heading-anchor-permalink" href="#Instructions" title="Permalink"></a></h2><p>If you have already cloned or downloaded the whole <a href="https://github.com/sylvaticus/SPMLJ/">course repository</a> the folder with the exercise is on <code>[REPOSITORY_ROOT]/lessonsMaterial/05_DT/creditApproval</code>. Otherwise download a zip of just that folder <a href="https://downgit.github.io/#/home?url=https://github.com/sylvaticus/SPMLJ/tree/main/lessonsMaterial/05_DT/creditApproval">here</a>.</p><p>In the folder you will find the file <code>creditApproval.jl</code> containing the Julia file that <strong>you will have to complete to implement the missing parts and run the file</strong> (follow the instructions on that file).  In that folder you will also find the <code>Manifest.toml</code> file. The proposal of resolution below has been tested with the environment defined by that file.   If you are stuck and you don&#39;t want to lookup to the resolution above you can also ask for help in the forum at the bottom of this page. Good luck! </p><h2 id="Resolution"><a class="docs-heading-anchor" href="#Resolution">Resolution</a><a id="Resolution-1"></a><a class="docs-heading-anchor-permalink" href="#Resolution" title="Permalink"></a></h2><p>Click &quot;ONE POSSIBLE SOLUTION&quot; to get access to (one possible) solution for each part of the code that you are asked to implement.</p><hr/><h3 id=")-Setting-up-the-environment..."><a class="docs-heading-anchor" href="#)-Setting-up-the-environment...">1) Setting up the environment...</a><a id=")-Setting-up-the-environment...-1"></a><a class="docs-heading-anchor-permalink" href="#)-Setting-up-the-environment..." title="Permalink"></a></h3><p>Start by setting the working directory to the directory of this file and activate it. If you have the provided <code>Manifest.toml</code> file in the directory, just run <code>Pkg.instantiate()</code>, otherwise manually add the packages <code>Pipe</code>, <code>HTTP</code>, <code>Plots</code>, <code>CSV</code>, <code>DataFrames</code>, and <code>BetaML</code>.</p><details><summary>ONE POSSIBLE SOLUTION</summary><pre><code class="language-julia hljs">cd(@__DIR__)         
using Pkg             
Pkg.activate(&quot;.&quot;)   
# If using a Julia version different than 1.7 please uncomment and run the following line (reproductibility guarantee will hower be lost)
# Pkg.resolve()   
Pkg.instantiate() 
using Random
Random.seed!(123)</code></pre></details><hr/><h3 id=")-Load-the-packages"><a class="docs-heading-anchor" href="#)-Load-the-packages">2) Load the packages</a><a id=")-Load-the-packages-1"></a><a class="docs-heading-anchor-permalink" href="#)-Load-the-packages" title="Permalink"></a></h3><p>Load the packages <code>Pipe</code>, <code>HTTP</code>, <code>Plots</code>, <code>CSV</code>, <code>DataFrames</code> and <code>BetaML</code>.</p><details><summary>ONE POSSIBLE SOLUTION</summary><pre><code class="language-julia hljs">using Pipe, HTTP, CSV, DataFrames, Plots, BetaML</code></pre></details><hr/><h3 id=")-Load-the-data"><a class="docs-heading-anchor" href="#)-Load-the-data">3) Load the data</a><a id=")-Load-the-data-1"></a><a class="docs-heading-anchor-permalink" href="#)-Load-the-data" title="Permalink"></a></h3><p>Load from internet or from local file the input data. You can use a pipeline from HTTP.get() to CSV.File to finally a DataFrame. Use the parameter <code>missingstring=&quot;?&quot;</code> in the <code>CSV.File()</code> call.</p><pre><code class="language-julia hljs">dataURL = &quot;https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data&quot;</code></pre><details><summary>ONE POSSIBLE SOLUTION</summary><pre><code class="language-julia hljs">data    = @pipe HTTP.get(dataURL).body |&gt; CSV.File(_,missingstring=&quot;?&quot;) |&gt; DataFrame</code></pre></details><hr/><h3 id=")-Write-the-feature-matrix-and-the-the-label-vector"><a class="docs-heading-anchor" href="#)-Write-the-feature-matrix-and-the-the-label-vector">4) Write the feature matrix and the the label vector</a><a id=")-Write-the-feature-matrix-and-the-the-label-vector-1"></a><a class="docs-heading-anchor-permalink" href="#)-Write-the-feature-matrix-and-the-the-label-vector" title="Permalink"></a></h3><p>Create the <code>X</code> matrix of features using the first to the second-to-last column of the data you loaded above and the <code>Y</code> vector by taking the last column. If you use the random forests algorithm suggested above, the only data preprocessing you need to do is to convert the X from a <code>DataFrame</code> to a <code>Matrix</code> and to <code>collect</code> the <code>Y</code> to a vector. Otherwise be sure to encode the categorical data, skip or impute the missing data and scale the feature matrix as required by the algorithm you employ.</p><p><em>[...] write your code here...</em></p><details><summary>ONE POSSIBLE SOLUTION</summary><pre><code class="language-julia hljs">(nR,nD) = size(data)

describe(data)
data = data[shuffle(1:nR),:]
X    = Matrix(data[:,1:end-1])
Y    = collect(data[:,end])</code></pre></details><hr/><h3 id=")-Partition-the-data"><a class="docs-heading-anchor" href="#)-Partition-the-data">5) Partition the data</a><a id=")-Partition-the-data-1"></a><a class="docs-heading-anchor-permalink" href="#)-Partition-the-data" title="Permalink"></a></h3><p>Partition your data in (<code>xtrain</code>,<code>xtest</code>) and (<code>ytrain</code>,<code>ytest</code>) (e.g. using 80% for the training and 20% for testing) You can use the BetaML <a href="https://sylvaticus.github.io/BetaML.jl/dev/Utils.html#BetaML.Api.partition-Union{Tuple{T},%20Tuple{AbstractVector{T},%20AbstractVector{Float64}}}%20where%20T%3C:AbstractArray"><code>partition()</code></a> function. Be sure to shuffle your data if you didn&#39;t do it earlier! (that&#39;s done by default)</p><p><em>[...] write your code here...</em></p><details><summary>ONE POSSIBLE SOLUTION</summary><pre><code class="language-julia hljs">((xtrain,xtest),(ytrain,ytest)) = partition([X,Y],[0.8,0.2])</code></pre></details><hr/><h3 id=")-(optional-but-suggested)-Tune-the-hyper-parameters"><a class="docs-heading-anchor" href="#)-(optional-but-suggested)-Tune-the-hyper-parameters">6) (optional but suggested) Tune the hyper-parameters</a><a id=")-(optional-but-suggested)-Tune-the-hyper-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#)-(optional-but-suggested)-Tune-the-hyper-parameters" title="Permalink"></a></h3><p>Find the best hyper-parameters for the model, i.e. the ones that lead to the highest accuracy under the records not used for training.</p><p>We can use the <a href="https://sylvaticus.github.io/BetaML.jl/dev/Utils.html#BetaML.Utils.crossValidation"><code>crossValidation</code></a> function here.</p><p>The idea is that for each hyper-parameter we have a range of possible values, and for each hyper-parameter, we first set <code>bestAcc=0.0</code> and then loop on each possible value, we run <code>crossValidation</code> with that particular value to compute the average training accuracy with that specific value under different data samples, and if it is better than the current <code>bestAcc</code>, we save it as the new <code>bestAcc</code> and the parameter value as the best value for that specific hyper-parameter. After we have found the best hyper-parameter value for one specific hyper-parameter, we can switch to the second hyper-parameter repeating the procedure but using the best value for the first hyper-parameter that we have found earlier, and we continue with the other hyper-parameters. Note that if we limit the hyper-parameter space sufficiently, we could also directly loop over all the possible combinations of hyper-parameters.</p><p>If you use the Random Forests from BetaML, consider the following hyper-parameter ranges:</p><pre><code class="language-julia hljs">nTrees_range             = 20:5:60
splittingCriterion_range = [gini,entropy]
maxDepth_range           = [10,15,20,25,30,500]
minRecords_range         = [1,2,3,4,5]
maxFeatures_range        = [2,3,4,5,6]
Î²_range                  = [0.0,0.5,1,2,5,10,20,50,100]</code></pre><p>To train a Random Forest in BetaML use: <code>myForest = buildForest(xtrain,ytrain, nTrees; &lt;other hyper-parameters&gt;)</code>.</p><p>And then to predict and compute the accuracy use:</p><pre><code class="language-julia hljs">Å·train=predict(myforest,xtrain)
trainAccuracy = accuracy(Å·train,ytrain)</code></pre><p>This activity is &quot;semi-optional&quot;, becauses Random Forests have already very good default values, so the gain we will likely obtain with tuning the various hyper-parameters is not expected to be very high. But it is a good exercise to arrive at this result by yourself !</p><p><em>[...] write your code here...</em></p><details><summary>ONE POSSIBLE SOLUTION</summary><pre><code class="language-julia hljs">sampler = KFold(nSplits=10,nRepeats=2)

nTrees_best             = 20
splittingCriterion_best = &quot;gini&quot;
maxDepth_best           = 10
minRecords_best         = 2
maxFeatures_best        = 3
Î²_best                  = 0.0

# Looking for hyper-parameters one at a time

# #### Number of trees
bestAcc = 0.0
accuracies = []
for nt in nTrees_range
    global nTrees_best, bestAcc, accuracies
    local acc
    print(&quot;Accuracy for $nt nTrees: &quot;)
    (acc,Ïƒ)    = crossValidation([xtrain,ytrain],sampler) do trainData,valData, rng
                    (xtrain,ytrain) = trainData; (xval,yval) = valData
                    forest          = buildForest(xtrain, ytrain, nt)
                    Å·val            = predict(forest,xval)
                    valAccuracy     = accuracy(Å·val,collect(yval))
                    return valAccuracy
                end
    if acc &gt; bestAcc
        bestAcc = acc
        nTrees_best = nt
    end
    push!(accuracies,acc)
    println(&quot;$acc (Ïƒ: $Ïƒ)&quot;)
end
plot(nTrees_range,accuracies,legend=nothing,ylabel=&quot;accuracy&quot;,xlabel=&quot;nTrees&quot;)

# #### Splitting criterion
bestAcc = 0.0
accuracies = []
for sc in splittingCriterion_range
    global splittingCriterion_best, bestAcc, accuracies
    local acc
    print(&quot;Accuracy for $sc splittingCriterion: &quot;)
    (acc,Ïƒ)    = crossValidation([xtrain,ytrain],sampler) do trainData,valData, rng
                    (xtrain,ytrain) = trainData; (xval,yval) = valData
                    forest          = buildForest(xtrain, ytrain, nTrees_best, splittingCriterion=sc)
                    Å·val            = predict(forest,xval)
                    valAccuracy     = accuracy(Å·val,collect(yval))
                    return valAccuracy
                end
    if acc &gt; bestAcc
        bestAcc = acc
        splittingCriterion_best = sc
    end
    push!(accuracies,acc)
    println(&quot;$acc (Ïƒ: $Ïƒ)&quot;)
end
bar(string.(splittingCriterion_range),accuracies,legend=nothing,ylabel=&quot;accuracy&quot;,xlabel=&quot;splititngCriterion&quot;)

# #### Max (tree) depth
bestAcc = 0.0
accuracies = []
for md in maxDepth_range
    global maxDepth_best, bestAcc, accuracies
    local acc
    print(&quot;Accuracy for $md maxDepth: &quot;)
    (acc,Ïƒ)    = crossValidation([xtrain,ytrain],sampler) do trainData,valData, rng
                    (xtrain,ytrain) = trainData; (xval,yval) = valData
                    forest          = buildForest(xtrain, ytrain, nTrees_best, splittingCriterion=splittingCriterion_best, maxDepth=md)
                    Å·val            = predict(forest,xval)
                    valAccuracy     = accuracy(Å·val,collect(yval))
                    return valAccuracy
                end
    if acc &gt; bestAcc
        bestAcc = acc
        maxDepth_best = md
    end
    push!(accuracies,acc)
    println(&quot;$acc (Ïƒ: $Ïƒ)&quot;)
end
plot(maxDepth_range,accuracies,legend=nothing,ylabel=&quot;accuracy&quot;,xlabel=&quot;maxDepth&quot;)
plot(maxDepth_range[1:end-1],accuracies[1:end-1],legend=nothing,ylabel=&quot;accuracy&quot;,xlabel=&quot;maxDepth&quot;)


# #### Min records per leaf
bestAcc = 0.0
accuracies = []
for mr in minRecords_range
    global minRecords_best, bestAcc, accuracies
    local acc
    print(&quot;Accuracy for $mr minRecords: &quot;)
    (acc,Ïƒ)    = crossValidation([xtrain,ytrain],sampler) do trainData,valData, rng
                    (xtrain,ytrain) = trainData; (xval,yval) = valData
                    forest          = buildForest(xtrain, ytrain, nTrees_best, splittingCriterion=splittingCriterion_best, maxDepth=maxDepth_best, minRecords=mr)
                    Å·val            = predict(forest,xval)
                    valAccuracy     = accuracy(Å·val,collect(yval))
                    return valAccuracy
                end
    if acc &gt; bestAcc
        bestAcc = acc
        minRecords_best = mr
    end
    push!(accuracies,acc)
    println(&quot;$acc (Ïƒ: $Ïƒ)&quot;)
end
plot(minRecords_range,accuracies,legend=nothing,ylabel=&quot;accuracy&quot;,xlabel=&quot;minRecords&quot;)

# #### Max features to consider in a tree
bestAcc = 0.0
accuracies = []
for mf in maxFeatures_range
    global mmaxFeatures_best, bestAcc, accuracies
    local acc
    print(&quot;Accuracy for $mf maxFeatures: &quot;)
    (acc,Ïƒ)    = crossValidation([xtrain,ytrain],sampler) do trainData,valData, rng
                    (xtrain,ytrain) = trainData; (xval,yval) = valData
                    forest          = buildForest(xtrain, ytrain, nTrees_best, splittingCriterion=splittingCriterion_best, maxDepth=maxDepth_best, maxFeatures=mf)
                    Å·val            = predict(forest,xval)
                    valAccuracy     = accuracy(Å·val,collect(yval))
                    return valAccuracy
                end
    if acc &gt; bestAcc
        bestAcc = acc
        maxFeatures_best = mf
    end
    push!(accuracies,acc)
    println(&quot;$acc (Ïƒ: $Ïƒ)&quot;)
end
plot(maxFeatures_range,accuracies,legend=nothing,ylabel=&quot;accuracy&quot;,xlabel=&quot;maxFeatures&quot;)

# #### Weigth for best trees representation
bestAcc = 0.0
accuracies = []
for b in Î²_range
    global Î²_best, bestAcc, accuracies
    local acc
    print(&quot;Accuracy for $b Î²: &quot;)
    (acc,Ïƒ)    = crossValidation([xtrain,ytrain],sampler) do trainData,valData, rng
                    (xtrain,ytrain) = trainData; (xval,yval) = valData
                    forest          = buildForest(xtrain, ytrain, nTrees_best, splittingCriterion=splittingCriterion_best, maxDepth=maxDepth_best, maxFeatures=maxFeatures_best, Î²=b)
                    Å·val            = predict(forest,xval)
                    valAccuracy     = accuracy(Å·val,collect(yval))
                    return valAccuracy
                end
    if acc &gt; bestAcc
        bestAcc = acc
        Î²_best = b
    end
    push!(accuracies,acc)
    println(&quot;$acc (Ïƒ: $Ïƒ)&quot;)
end
plot(Î²_range,accuracies,legend=nothing,ylabel=&quot;accuracy&quot;,xlabel=&quot;Î²&quot;)</code></pre></details><hr/><h3 id=")-Train-and-evaluate-the-final-model"><a class="docs-heading-anchor" href="#)-Train-and-evaluate-the-final-model">7) Train and evaluate the final model</a><a id=")-Train-and-evaluate-the-final-model-1"></a><a class="docs-heading-anchor-permalink" href="#)-Train-and-evaluate-the-final-model" title="Permalink"></a></h3><p>Perform the final training with the best hyperparameters and compute the accuracy on the test set If you have chosen good hyperparameters, your accuracy should be in the 98%-99% range for training and 81%-89% range for testing </p><p><em>[...] write your code here...</em></p><details><summary>ONE POSSIBLE SOLUTION</summary><pre><code class="language-julia hljs">forest = buildForest(xtrain, ytrain, nTrees_best, splittingCriterion=splittingCriterion_best, maxDepth=maxDepth_best, maxFeatures=maxFeatures_best)
Å·train = predict(forest,xtrain)
Å·test  = predict(forest,xtest)
trainAccuracy = accuracy(Å·train,ytrain)
testAccuracy  = accuracy(Å·test,ytest)

# To compare, using the default values and a single Decision Tree:

# default values..
forest = buildForest(xtrain, ytrain)
Å·train = predict(forest,xtrain)
Å·test  = predict(forest,xtest)
trainAccuracy = accuracy(Å·train,ytrain)
testAccuracy  = accuracy(Å·test,ytest)

# single decision tree..
tree = buildTree(xtrain, ytrain)
Å·train = predict(tree,xtrain)
Å·test  = predict(tree,xtest)
trainAccuracy = accuracy(Å·train,ytrain)
testAccuracy  = accuracy(Å·test,ytest)</code></pre></details><hr/><div id="pd_rating_holder_8962705"></div>
<script type="text/javascript">
PDRTJS_settings_8962705 = {
"id" : "8962705",
"unique_id" : "/home/runner/work/SPMLJ/SPMLJ/lessonsSources/05_-_DT_-_Decision_trees_based_algorithms/0502x_EXERCISE-5.1.md",
"title" : "0502x_EXERCISE-5.1.md",
"permalink" : ""
};
</script><div class="addthis_inline_share_toolbox"></div><hr/><script src="https://utteranc.es/client.js"
        repo="sylvaticus/SPMLJ"
        issue-term="title"
        label="ðŸ’¬ website_comment"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script><script type="text/javascript" charset="utf-8" src="https://polldaddy.com/js/rating/rating.js"></script><!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-6256c971c4f745bc"></script></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="0501_-_Decision_trees_based_algorithms.html">Â« 0501 - Decision trees based algorithms</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.15 on <span class="colophon-date" title="Sunday 24 April 2022 09:58">Sunday 24 April 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
